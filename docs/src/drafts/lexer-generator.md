---
title: Lexer Generator
permalink: /practicas/lexer-generator
published: true
date: 2022/03/22
delivery: "2022/03/31"
order: 11
layout: Practica
prev: egg-parser.md
sidebar: true
template: "https://github.com/crguezl/egg-parser-template"
rubrica:
  - El paquete est√° publicado en GitHub Registry
  - "Opcional: La funci√≥n exportada se llama con un array de pares `[[NAME, /(?<NAME>, ...)/] ... ]` en la que el nombre del token aparece repetido dos veces. Modifique la interfaz para que reciba s√≥lo un array de expresiones regulares con nombre `[/(?<NAME> ...)/, ... ]`"
  - El m√≥dulo exporta las funciones adecuadas
  - Contiene suficientes tests 
  - "Opcional: estudio de covering"
  - Se ha hecho CI con GitHub Actions
  - Los informes est√°n bien presentados
  - "La documentaci√≥n es completa" 
  - "Opcional: publicar la documentaci√≥n de la API usando GitHub Pages en la carpeta `docs/`"
  - Las *pruebas de producci√≥n* funcionan bien
  - El superproyecto est√° correctamente estructurado usando subm√≥dulos
  - Se ha hecho un buen uso del versionado sem√°ntico en la evoluci√≥n del m√≥dulo
  - "Opcional: se proporciona informaci√≥n de localizaci√≥n (offset, etc.)"
  - Manejo de errores y blancos
  - Calidad del c√≥digo
video:
  clase20200401: gO49wnWoE_s 
  clase20200325: 4jmsZbEpW7g
  clase20200324: xCNs1fT1KOc
---

## Objetivos

Usando el repo de la asignaci√≥n de esta tarea construya un paquete npm y 
publ√≠quelo como paquete privado en GitHub Registry con √°mbito `@ULL-ESIT-PL-2122`  y con nombre el nombre de su repo `lexgen-code-aluAtGitHub`

Una parte de los conceptos y habilidades a ejercitar con esta pr√°ctica se explican en la secci√≥n [Creating and publishing a node.js module en GitHub y en NPM](/temas/introduccion-a-javascript/creating-and-publishing-npm-module). 

El m√≥dulo deber√° exportar una funci√≥n que construye analizadores l√©xicos:

```js
const buildLexer =require('@ULL-ESIT-PL-2122/lexgen-code-aluAtGitHub');
```

La funci√≥n importada `buildLexer` se llamar√° con un array de expresiones regulares.
Cada una de las expresiones regulares deber√° ser un par√©ntesis con nombre.
El nombre del par√©ntesis es el nombre del token/terminal.

```js 
  const SPACE = /(?<SPACE>\s+|\/\/.*)/;
  const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
  const ID = /(?<ID>\b([a-z_]\w*)\b)/;
  const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
  const OP = /(?<OP>[+*\/=-])/;

  const myTokens = [ {match: SPACE, ignore: true}, RESERVEDWORD, ID, STRING, OP ];
```

Este array describe el l√©xico del lenguaje. La llamada `buildLexer(myTokens)` retornar√° una funci√≥n `lexer` que es el analizador l√©xico

```js
const lexer = buildLexer(myTokens);
```

Se establecen las siguientes consideraciones sem√°nticas:

* Si un token es un objeto y tiene la propedad  `ignore: true` sus matching ser√°n ignorados y no se a√±adir√°n a la lista de tokens 
* El token `ERROR` es especial y es autom√°ticamente retornado por el analizador l√©xico generado `lexer` en el caso de que la  entrada contenga un error
* Si en la lista aparece un token de la forma `EOF: SomeValue` el token `EOF` ser√° retornado cuando se alcance el final de la entrada con valor asociado `SomeValue`. En otro caso se retornar√° `null` para indicar el final de la entrada

Este es un ejemplo mas concreto de como usar la librer√≠a:

```js
const buildLexer = require('@ull-esit-pl-1920/p10-t2-lexgen-code-aluXXX');

const SPACE = /(?<SPACE>\s+|\/\/.*)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

const lexer = buildLexer(myTokens);
```

cuando `lexer` es llamada con una cadena de entrada retorna la secuencia de tokens de esa cadena conforme a la descripci√≥n l√©xica prove√≠da:

```js
str = 'const varName = "value"';
r = lexer(str);
let expected = [
  { type: 'RESERVEDWORD', value: 'const' },
  { type: 'ID', value: 'varName' },
  { type: 'OP', value: '=' },
  { type: 'STRING', value: '"value"' }
];

test(str, () => {
  expect(r).toEqual(expected);
});
```

Cuando se encuentra una entrada err√≥nea `lexer ` produce un token con nombre `ERROR`:

```js
str = ' // Entrada con errores\nlet x = 42*c';
r = lexer(str);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ERROR', value: '42*c' }
];
```

Esta entrada es err√≥nea por cuanto no hemos definido el token para los n√∫meros.
El token `ERROR` es especial en cuanto con que casa con cualquier entrada err√≥nea.

V√©ase tambi√©n el √∫ltimo ejemplo con errores en la [secci√≥n Pruebas](#pruebas)

## Prerequisitos

T√≥me esta pr√°ctica con calma por cuanto me parece es  complicada en el estado de conocimientos de RegExps en el que estamos. 
Nos ha faltado una clase para establecer las bases necesarias.

En este v√≠deo se introducen los conceptos de expresiones regulares que son necesarios
para la realizaci√≥n de esta pr√°ctica. Especialmente 

* `lastindex` en el minuto 19:30 
* El uso de la sticky flag `/y` a partir del minuto 30
* Construcci√≥n de analizador l√©xico minuto 33:45

<youtube id="xCNs1fT1KOc"></youtube>

En  los primeros 25 minutos de este v√≠deo se explica como realizar la pr√°ctica:

* Analizadores L√©xicos: 03:00
<youtube id="4jmsZbEpW7g"></youtube>

Est√∫dielos antes de seguir adelante

<!--
## Descripci√≥n del Lenguaje L√©xico: par√°metros de entrada de la funci√≥n 

El l√©xico del lenguaje se describe mediante un array de pares `[String, /regExp/]`:

```js
[[nombreDelToken1, /regExpDelToken1/] ... [nombreDelTokenN, /regExpDelTokenN/]
```

Sigue un ejemplo de descripci√≥n de un analizador l√©xico 
para un peque√±o lenguaje:

```js
const SPACE = /(?<SPACE>\s+)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

```
-->

## Sugerencias

Puede partir de este c√≥digo en el que se combina el uso de sticky y los grupos con nombre


```js
const str = 'const varName = "value"';
console.log(str);

const SPACE = /(?<SPACE>\s+)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>([a-z_]\w+))/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const tokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID], 
  ['STRING', STRING], ['OP', OP] 
];

const tokenNames = tokens.map(t => t[0]);
const tokenRegs  = tokens.map(t => t[1]);

const buildOrRegexp = (regexps) => {
  const sources = regexps.map(r => r.source);
  const union = sources.join('|');
  // console.log(union);
  return new RegExp(union, 'y');
};

const regexp = buildOrRegexp(tokenRegs);

const getToken = (m) => tokenNames.find(tn => typeof m[tn] !== 'undefined');

let match;
while (match = regexp.exec(str)) {
  //console.log(match.groups);
  let t = getToken(match.groups);
  console.log(`Found token '${t}' with value '${match.groups[t]}'`);
}
```

escribiendo una funci√≥n `makeLexer` que recibe como argumentos un array `tokens`
como en el ejemplo y retorna una funci√≥n que hace el an√°lisis l√©xico 
correspondiente a esos tokens.

## Pruebas

Deber√° a√±adir pruebas usando [Jest](/temas/introduccion-a-javascript/jest}). Ampl√≠e este ejemplo:

```
[~/.../github-actions-learning/lexer-generator(master)]$ pwd -P
/Users/casiano/local/src/github-actions-learning/lexer-generator
[~/.../github-actions-learning/lexer-generator(master)]$ cat test.js
```
```js
// If you want debugging output run it this way:
// DEBUG=1 npm test
const debug = process.env["DEBUG"];
const { inspect } = require('util');
const ins = (x) => { if (debug) console.log(inspect(x, {depth: null})) };

const buildLexer =require('./index');

const SPACE = /(?<SPACE>\s+|\/\/.*)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

let str, lexer, r;
lexer = buildLexer(myTokens);

str = 'const varName = "value"';
ins(str);
r = lexer(str);
ins(r);
let expected = [
  { type: 'RESERVEDWORD', value: 'const' },
  { type: 'ID', value: 'varName' },
  { type: 'OP', value: '=' },
  { type: 'STRING', value: '"value"' }
];

test(str, () => {
  expect(r).toEqual(expected);
});

str = 'let x = a + \nb';
ins(str);
r = lexer(str);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ID', value: 'a' },
  { type: 'OP', value: '+' },
  { type: 'ID', value: 'b' }
];
ins(r);
test(str, () => {
  expect(r).toEqual(expected);
});

str = ' // Entrada con errores\nlet x = 42*c';
ins(str);
r = lexer(str);
ins(r);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ERROR', value: '42*c' }
];

test(str, () => {
  expect(r).toEqual(expected);
});
```

Ejemplo de ejecuci√≥n:

```
[~/.../github-actions-learning/lexer-generator(master)]$ npm test

> @ULL-ESIT-PL-2122/lexer-generator@1.0.0 test /Users/casiano/local/src/github-actions-learning/lexer-generator
> jest        üëà use jest!

 PASS  ./test.js
  ‚úì const varName = "value" (4ms)
  ‚úì let x = a +
b
  ‚úì  // Entrada con errores
let x = 42*c (1ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        1.126s
Ran all test suites.
```

## Integraci√≥n Cont√≠nua usando GitHub Actions

Use [GitHub Actions](/temas/introduccion-a-javascript/github-actions) para la ejecuci√≥n de las pruebas

## Documentaci√≥n

[Documente](/assets/temas/introduccion-a-javascript/documentation)
el m√≥dulo incorporando un `README.md` y la documentaci√≥n de la funci√≥n exportada.

## Publicar como paquete npm en GitHub Registry

Usando el repo de la asignaci√≥n de esta tarea publique el paquete como paquete privado en GitHub Registry con √°mbito `@ULL-ESIT-PL-2122`  y nombre el nombre de su repo `lexgen-code-aluAtGitHub`

## Pruebas de Producci√≥n

En un nuevo repo `lexgen-testing-aluGitHub` a√±ada las pruebas
para comprobar que el paquete publicado 
se instala y puede ser usado correctamente.

Usando `git submodule` configure un super-repo para que contenga
a ambos repos: el del m√≥dulo `lexgen-code-aluAtGitHub` y el repo de pruebas de producci√≥n `lexgen-testing-aluGitHub`.

## Semantic Versioning

* Publique una mejora en la funcionalidad del m√≥dulo. Por ejemplo a√±ada la opci√≥n `/u`
a la expresi√≥n regular creada para que Unicode sea soportado. ¬øComo debe cambiar el n¬∫ de versi√≥n?

* Opcional: Un defecto que tiene el dise√±o del m√≥dulo es que el nombre de la expresi√≥n regular que define el token aparece dos veces: dentro de la regexp y en el array y debe ser la misma. Cambie la interfaz para que s√≥lo aparezca una vez. ¬øComo debe cambiar el n¬∫ de versi√≥n?

<!--
## Mejoras 2022

* Nos. de l√≠nea
* Transformers
* next (compatibilidad con nearley)
* reset(chunk, info) sets the internal buffer of the lexer to chunk, and restores its state to a state returned by save().
* formatError(token)
* has(name) returns true if the lexer can emit tokens with that name. This is used to resolve %-specifiers in compiled nearley grammars.
-->

## Referencias

* Tema [Expresiones Regulares y An√°lisis L√©xico]({{site.baseurl}}/temas/expresiones-regulares-y-analisis-lexico)  
* Secci√≥n [Creating and publishing a node.js module en GitHub y en NPM](/temas/introduccion-a-javascript/creating-and-publishing-npm-module)
* [Jest](/temas/introduccion-a-javascript/jest)
* Secci√≥n [GitHub Registry](/temas/introduccion-a-javascript/github-registry)
* Secci√≥n [GitHub Actions](/temas/introduccion-a-javascript/github-actions)
* Secci√≥n [M√≥dulos](/temas/introduccion-a-javascript/modulos)
* Secci√≥n [Node.js Packages](/temas/introduccion-a-javascript/nodejspackages)
* Secci√≥n [Documentation](/temas/introduccion-a-javascript/documentation)
